# Theory of Machine Learning Regression

![image-20241224011500296](D:\Mirror\PostgraduateCourse\01应用统计学\Homework\Homework Final\comparison.png)

![在这里插入图片描述](D:\Mirror\PostgraduateCourse\01应用统计学\Homework\Homework Final\02457baca5666466d1f3415e17f1e82a.png)

## 决策树

![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/f155a644e51fa69492b0d2be723a9cd7.png)

## 随机森林

![img](D:\Mirror\PostgraduateCourse\01应用统计学\Homework\Homework Final\RandomForest.png)

## Adaboost

[AdaBoost](https://so.csdn.net/so/search?q=AdaBoost&spm=1001.2101.3001.7020)是典型的Boosting算法。

[Boosting算法](https://so.csdn.net/so/search?q=Boosting算法&spm=1001.2101.3001.7020)是将“弱学习算法“提升为“强学习算法”的过程，主要思想是“三个臭皮匠顶个诸葛亮”。

一般来说，找到弱学习算法要相对容易一些，然后通过反复学习得到一系列弱[分类器](https://so.csdn.net/so/search?q=分类器&spm=1001.2101.3001.7020)，组合这些弱分类器得到一个强分类器。

![img](https://i-blog.csdnimg.cn/blog_migrate/9db43b027474901a1daa2cbfdf2ad8e0.png)

## GBDT

集成学习-Boosting

弱学习器对残差进行预测，最后求和

![img](D:\Mirror\PostgraduateCourse\01应用统计学\Homework\Homework Final\GBDT.png)

## Extra Tree 极端随机树

 Extra Trees 在构建每棵决策树时，不仅随机选择特征子集，对于所选特征子集里的每个特征，**划分阈值也是随机产生**，然后从这些随机产生的划分方案中选择一个最优的（比如根据某种不纯度衡量指标，像基尼系数等）来进行节点划分。

## BP神经网络

## XGBoost

XGBoost的目标是通过优化一个加权的损失函数来提升模型的性能。XGBoost的目标函数可以分为两部分：

- **损失函数**：衡量模型在训练数据上的误差，通常是均方误差（MSE）或者对数损失等。
- **正则化项**：为了防止过拟合，XGBoost引入了正则化项，通常包括树的复杂度（如树的深度、叶节点的数量等）。正则化项的引入有助于提高模型的泛化能力。

## 

## 结论

- 机器学习方法：机器学习方法比传统的线性回归方法效果更佳。
- 集成学习方法：集成学习在训练效率和模型效果上均优于BP神经网络。

- 不同的集成学习方法：支持向量机不适用于处理该问题；在计算时间充足的情况下， cat boost、extra tree 和 lightgbm 在处理本问题上效果更好；而考虑到训练用时，改良的GBDT算法（lightgbm、catboost和XGboost）的训练速度明显更快（30s以内）。
- 垂直方向的飞行数据（位置、速度、加速度）在各种模型中具有更高的重要性，对功率的影响较大；其次是载荷和风速。

- 需要较大量的数据（10w行以上）提升模型性能并避免过拟合。



对无人机飞行数据进行了初步数据清洗和描述性统计分析

采用因子分析、回归分析的方法分析文献中的无人机能耗模型

采用聚类分析对无人机飞行姿态进行分类，并考虑聚类结果等因素进行进一步清洗

采用相关性分析、主成分分析、正太性和齐方差性检验的方法对无人机瞬时功率进行拟合

最后，采用决策树、随机森林、extra tree、adaboost、GBDT、XGboost、catboost、lightgbm等机器学习方法对无人机瞬时功率进行回归。

